{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q1: Write a python program to scrape data for “Data Analyst” Job position in“Bangalore” location. You have to scrape the job-title, job-location, company_name, experience_required. You have to scrape first 10 jobs data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import selenium\n",
    "import pandas as pd\n",
    "from selenium import webdriver\n",
    "import time\n",
    "# Opening Browsers in Incognito using Options\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "chrome_options = Options()\n",
    "chrome_options.add_argument('--incognito')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function opens the naukri home page and searches for 'Data Analyst' and 'Bangalore'\n",
    "\n",
    "def naukri(url):\n",
    "    driver=webdriver.Chrome(r\"C:\\Users\\dheerajkumar_pittala\\DataPy\\Browserdrivers\\chromedriver.exe\")\n",
    "    # 1. first get the webpage https://www.naukri.com/\n",
    "    driver.get(url)\n",
    "    \n",
    "    # 2. Enter “Data Analyst” in “Skill,Designations,Companies” field \n",
    "    job_search=driver.find_element_by_id('qsb-keyword-sugg')\n",
    "    job_search.send_keys(\"Data Analyst\")\n",
    "    \n",
    "    # and enter “Bangalore” in “enter the location” field \n",
    "    location_search=driver.find_element_by_xpath(\"//input[@id='qsb-location-sugg']\")\n",
    "    location_search.send_keys(\"Bangalore\")\n",
    " \n",
    "    # 3. Then click the search button\n",
    "    search_buton=driver.find_element_by_xpath(\"//div[@class='search-btn']/button\")\n",
    "    search_buton.click()\n",
    "    time.sleep(5)\n",
    "\n",
    "    # 4. Then scrape the data for the first 10 jobs results you get.\n",
    "    job_titles=[]\n",
    "    title_tags=driver.find_elements_by_xpath(\"//a[@class='title fw500 ellipsis']\")[:10]\n",
    "    for i in title_tags:\n",
    "        job_titles.append(i.text)\n",
    "    \n",
    "    company_names=[]\n",
    "    company_tags=driver.find_elements_by_xpath(\"//a[@class='subTitle ellipsis fleft']\")[:10]\n",
    "    for i in company_tags:\n",
    "        company_names.append(i.text)\n",
    "        \n",
    "    experience_list=[]\n",
    "    exp_tags=driver.find_elements_by_xpath(\"//li[@class='fleft grey-text br2 placeHolderLi experience']/span\")[:10]\n",
    "    for i in exp_tags:\n",
    "        experience_list.append(i.text)\n",
    "        \n",
    "    salary_list=[]\n",
    "    sal_tags=driver.find_elements_by_xpath(\"//li[@class='fleft grey-text br2 placeHolderLi salary']/span\")[:10]\n",
    "    for i in sal_tags:\n",
    "        salary_list.append(i.text)\n",
    "        \n",
    "    locations_list=[]\n",
    "    loc_tags=driver.find_elements_by_xpath(\"//li[@class='fleft grey-text br2 placeHolderLi location']/span\")[:10]\n",
    "    for i in loc_tags:\n",
    "        locations_list.append(i.text)\n",
    "        \n",
    "    jobs=pd.DataFrame({})\n",
    "    jobs['job_titles']=job_titles\n",
    "    jobs['company_names']=company_names\n",
    "    jobs['locations_list']=locations_list\n",
    "    jobs['experience_list']=experience_list\n",
    "    jobs['salary_list']=salary_list\n",
    "    \n",
    "    driver.close()\n",
    "    return(jobs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>job_titles</th>\n",
       "      <th>company_names</th>\n",
       "      <th>locations_list</th>\n",
       "      <th>experience_list</th>\n",
       "      <th>salary_list</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>Senior Data Analyst</td>\n",
       "      <td>Gaussian Networks Private Limited</td>\n",
       "      <td>Gurgaon/Gurugram, Bangalore/Bengaluru</td>\n",
       "      <td>3-5 Yrs</td>\n",
       "      <td>Not disclosed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>Tcs Hiring For Senior Data Analyst (bfsi domain)</td>\n",
       "      <td>Tata Consultancy Services Ltd.</td>\n",
       "      <td>Chennai, Bangalore/Bengaluru</td>\n",
       "      <td>6-11 Yrs</td>\n",
       "      <td>Not disclosed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>Business Data Analyst</td>\n",
       "      <td>Trigent Software</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>5-10 Yrs</td>\n",
       "      <td>Not disclosed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>Business Data Analyst</td>\n",
       "      <td>Trigent Software</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>5-10 Yrs</td>\n",
       "      <td>Not disclosed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>Business Data Analyst - Google Data Studio &amp; SQL</td>\n",
       "      <td>AVE-Promagne</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>3-8 Yrs</td>\n",
       "      <td>Not disclosed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>Senior Data Analyst</td>\n",
       "      <td>Virtusa Consulting Services Pvt Ltd</td>\n",
       "      <td>Hyderabad/Secunderabad, Pune, Gurgaon/Gurugram...</td>\n",
       "      <td>8-12 Yrs</td>\n",
       "      <td>Not disclosed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>Tcs Hiring For MDM (master data management) Da...</td>\n",
       "      <td>Tata Consultancy Services Ltd.</td>\n",
       "      <td>(WFH during Covid)</td>\n",
       "      <td>6-11 Yrs</td>\n",
       "      <td>Not disclosed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>Senior Data Analyst IDAM Services</td>\n",
       "      <td>GlaxoSmithKline Pharmaceuticals Limited</td>\n",
       "      <td>Chennai, Bangalore/Bengaluru</td>\n",
       "      <td>4-8 Yrs</td>\n",
       "      <td>Not disclosed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>Data Analyst/Sr.Data Engineer</td>\n",
       "      <td>SYREN TECHNOLOGIES PRIVATE LIMITED</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>4-9 Yrs</td>\n",
       "      <td>10,00,000 - 20,00,000 PA.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>SENIOR DATA ANALYST</td>\n",
       "      <td>McAfee Software (India) Pvt. Ltd</td>\n",
       "      <td>Hyderabad/Secunderabad, Chennai, Bangalore/Ben...</td>\n",
       "      <td>6-8 Yrs</td>\n",
       "      <td>Not disclosed</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          job_titles  \\\n",
       "0                                Senior Data Analyst   \n",
       "1   Tcs Hiring For Senior Data Analyst (bfsi domain)   \n",
       "2                              Business Data Analyst   \n",
       "3                              Business Data Analyst   \n",
       "4   Business Data Analyst - Google Data Studio & SQL   \n",
       "5                                Senior Data Analyst   \n",
       "6  Tcs Hiring For MDM (master data management) Da...   \n",
       "7                  Senior Data Analyst IDAM Services   \n",
       "8                      Data Analyst/Sr.Data Engineer   \n",
       "9                                SENIOR DATA ANALYST   \n",
       "\n",
       "                             company_names  \\\n",
       "0        Gaussian Networks Private Limited   \n",
       "1           Tata Consultancy Services Ltd.   \n",
       "2                         Trigent Software   \n",
       "3                         Trigent Software   \n",
       "4                             AVE-Promagne   \n",
       "5      Virtusa Consulting Services Pvt Ltd   \n",
       "6           Tata Consultancy Services Ltd.   \n",
       "7  GlaxoSmithKline Pharmaceuticals Limited   \n",
       "8       SYREN TECHNOLOGIES PRIVATE LIMITED   \n",
       "9         McAfee Software (India) Pvt. Ltd   \n",
       "\n",
       "                                      locations_list experience_list  \\\n",
       "0              Gurgaon/Gurugram, Bangalore/Bengaluru         3-5 Yrs   \n",
       "1                       Chennai, Bangalore/Bengaluru        6-11 Yrs   \n",
       "2                                Bangalore/Bengaluru        5-10 Yrs   \n",
       "3                                Bangalore/Bengaluru        5-10 Yrs   \n",
       "4                                Bangalore/Bengaluru         3-8 Yrs   \n",
       "5  Hyderabad/Secunderabad, Pune, Gurgaon/Gurugram...        8-12 Yrs   \n",
       "6                                 (WFH during Covid)        6-11 Yrs   \n",
       "7                       Chennai, Bangalore/Bengaluru         4-8 Yrs   \n",
       "8                                Bangalore/Bengaluru         4-9 Yrs   \n",
       "9  Hyderabad/Secunderabad, Chennai, Bangalore/Ben...         6-8 Yrs   \n",
       "\n",
       "                 salary_list  \n",
       "0              Not disclosed  \n",
       "1              Not disclosed  \n",
       "2              Not disclosed  \n",
       "3              Not disclosed  \n",
       "4              Not disclosed  \n",
       "5              Not disclosed  \n",
       "6              Not disclosed  \n",
       "7              Not disclosed  \n",
       "8  10,00,000 - 20,00,000 PA.  \n",
       "9              Not disclosed  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=naukri('https://www.naukri.com/')\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q2. Write a python program to scrape data for “Data Scientist” Job position in “Bangalore” location. You have to scrape the job-title, job-location, company_name, full job-description. You have to scrape first 10 jobs data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: selenium in c:\\users\\dheerajkumar_pittala\\appdata\\local\\continuum\\anaconda3\\lib\\site-packages (3.141.0)\n",
      "Requirement already satisfied: urllib3 in c:\\users\\dheerajkumar_pittala\\appdata\\local\\continuum\\anaconda3\\lib\\site-packages (from selenium) (1.24.2)\n",
      "Requirement already satisfied: webdriver-manager in c:\\users\\dheerajkumar_pittala\\appdata\\local\\continuum\\anaconda3\\lib\\site-packages (3.4.2)\n",
      "Requirement already satisfied: requests in c:\\users\\dheerajkumar_pittala\\appdata\\local\\continuum\\anaconda3\\lib\\site-packages (from webdriver-manager) (2.22.0)\n",
      "Requirement already satisfied: configparser in c:\\users\\dheerajkumar_pittala\\appdata\\local\\continuum\\anaconda3\\lib\\site-packages (from webdriver-manager) (5.0.2)\n",
      "Requirement already satisfied: crayons in c:\\users\\dheerajkumar_pittala\\appdata\\local\\continuum\\anaconda3\\lib\\site-packages (from webdriver-manager) (0.4.0)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in c:\\users\\dheerajkumar_pittala\\appdata\\local\\continuum\\anaconda3\\lib\\site-packages (from requests->webdriver-manager) (1.24.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\dheerajkumar_pittala\\appdata\\local\\continuum\\anaconda3\\lib\\site-packages (from requests->webdriver-manager) (2019.9.11)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in c:\\users\\dheerajkumar_pittala\\appdata\\local\\continuum\\anaconda3\\lib\\site-packages (from requests->webdriver-manager) (3.0.4)\n",
      "Requirement already satisfied: idna<2.9,>=2.5 in c:\\users\\dheerajkumar_pittala\\appdata\\local\\continuum\\anaconda3\\lib\\site-packages (from requests->webdriver-manager) (2.8)\n",
      "Requirement already satisfied: colorama in c:\\users\\dheerajkumar_pittala\\appdata\\local\\continuum\\anaconda3\\lib\\site-packages (from crayons->webdriver-manager) (0.4.1)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "! pip install selenium\n",
    "import selenium\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "!pip install webdriver-manager\n",
    "from selenium import webdriver\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "from selenium.webdriver.common.keys import Keys \n",
    "from selenium.common.exceptions import ElementClickInterceptedException\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#let's connect to the webdriver\n",
    "\n",
    "driver= webdriver.Chrome(r'C:\\Users\\dheerajkumar_pittala\\DataPy\\Browserdrivers\\chromedriver.exe')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.get('https://www.naukri.com/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_job=driver.find_element_by_id('qsb-keyword-sugg')\n",
    "search_job.send_keys('Data Scientist')\n",
    "search_loc=driver.find_element_by_xpath(\"//input[@id='qsb-location-sugg']\")\n",
    "search_loc.send_keys('Bangalore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "search_btn=driver.find_element_by_xpath(\"//div[@class='search-btn']/button\")\n",
    "search_btn.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "url='https://www.naukri.com/data-scientist-jobs-in-bangalore?k=data%20scientist&l=bangalore'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "job_titles=[]\n",
    "company_names=[]\n",
    "location_list=[]\n",
    "full_job_description=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<selenium.webdriver.remote.webelement.WebElement (session=\"043dcbba969ca0c694e48489f1d244d8\", element=\"619d0113-931a-44e6-9595-480055e9c09c\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"043dcbba969ca0c694e48489f1d244d8\", element=\"1774dd68-3d49-4ede-a3c7-faaeca0ec76a\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"043dcbba969ca0c694e48489f1d244d8\", element=\"e72e0d2a-e06a-4186-a4cf-caf8f78f87da\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"043dcbba969ca0c694e48489f1d244d8\", element=\"fad5fada-dccb-4de8-9f76-153661918142\")>]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "titles_tags=driver.find_elements_by_xpath(\"//a[@class='title fw500 ellipsis']\")\n",
    "titles_tags[0:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Hiring For Data Scientist',\n",
       " 'Lead Data Scientist BFSI',\n",
       " 'Associate Data Scientist',\n",
       " 'Data Scientist']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for i in titles_tags:\n",
    "    title=i.text\n",
    "    job_titles.append(title)\n",
    "    \n",
    "job_titles[0:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<selenium.webdriver.remote.webelement.WebElement (session=\"043dcbba969ca0c694e48489f1d244d8\", element=\"9882c7e7-0f0a-4d08-ab61-a2a436a70e07\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"043dcbba969ca0c694e48489f1d244d8\", element=\"a9f3b573-cba7-4b98-9166-01e72a491774\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"043dcbba969ca0c694e48489f1d244d8\", element=\"e7354158-ab0d-4ead-b7ec-b956e358bcae\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"043dcbba969ca0c694e48489f1d244d8\", element=\"727dd02a-3f4a-488f-a5ab-5274d34dcdbf\")>]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "companies_tags=driver.find_elements_by_xpath(\"//a[@class='subTitle ellipsis fleft']\")\n",
    "companies_tags[0:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Tata Consultancy Services Ltd.',\n",
       " 'IBM India Pvt. Limited',\n",
       " 'Philips India Limited',\n",
       " 'Brillio']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for i in companies_tags:\n",
    "    company=i.text\n",
    "    company_names.append(company)\n",
    "    \n",
    "company_names[0:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<selenium.webdriver.remote.webelement.WebElement (session=\"043dcbba969ca0c694e48489f1d244d8\", element=\"40b9955b-8973-4af2-b691-3d5d7562f3d4\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"043dcbba969ca0c694e48489f1d244d8\", element=\"240e9879-1e72-4221-9ec7-249e2281489d\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"043dcbba969ca0c694e48489f1d244d8\", element=\"55afc9b6-c4f2-454d-a920-cb41fca6bdf6\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"043dcbba969ca0c694e48489f1d244d8\", element=\"76cfaf43-d924-4bcd-a6be-bc645fa61f59\")>]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "location_tags=driver.find_elements_by_xpath(\"//li[@class='fleft grey-text br2 placeHolderLi location']/span[1]\")\n",
    "location_tags[0:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Chennai, Bangalore/Bengaluru, Mumbai (All Areas)',\n",
       " 'Bengaluru/Bangalore',\n",
       " 'Bangalore/Bengaluru',\n",
       " 'Bangalore/Bengaluru']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for i in location_tags:\n",
    "    location=i.text\n",
    "    location_list.append(location)\n",
    "    \n",
    "location_list[0:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "href1=[]\n",
    "\n",
    "for elem in titles_tags:\n",
    "    href = elem.get_attribute('href')\n",
    "    if href is not None:\n",
    "        href1.append(href)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['https://www.naukri.com/job-listings-hiring-for-data-scientist-tata-consultancy-services-chennai-bangalore-bengaluru-mumbai-all-areas-3-to-8-years-110921000464?src=jobsearchDesk&sid=1631543662342285&xp=1&px=1',\n",
       " 'https://www.naukri.com/job-listings-lead-data-scientist-bfsi-ibm-india-pvt-limited-bengaluru-bangalore-5-to-9-years-070921901691?src=jobsearchDesk&sid=1631543662342285&xp=2&px=1',\n",
       " 'https://www.naukri.com/job-listings-associate-data-scientist-philips-india-limited-bangalore-bengaluru-3-to-5-years-060921501985?src=jobsearchDesk&sid=1631543662342285&xp=3&px=1',\n",
       " 'https://www.naukri.com/job-listings-data-scientist-brillio-technologies-pvt-ltd-bangalore-bengaluru-3-to-8-years-130921905402?src=jobsearchDesk&sid=1631543662342285&xp=4&px=1',\n",
       " 'https://www.naukri.com/job-listings-data-scientist-i-ii-sharechat-bangalore-bengaluru-2-to-3-years-130921500157?src=jobsearchDesk&sid=1631543662342285&xp=5&px=1',\n",
       " 'https://www.naukri.com/job-listings-data-scientist-allegis-services-india-pvt-ltd-bangalore-bengaluru-4-to-8-years-130921603395?src=jobsearchDesk&sid=1631543662342285&xp=6&px=1',\n",
       " 'https://www.naukri.com/job-listings-data-scientist-allegis-services-india-pvt-ltd-bangalore-bengaluru-4-to-8-years-130921003393?src=jobsearchDesk&sid=1631543662342285&xp=7&px=1',\n",
       " 'https://www.naukri.com/job-listings-data-scientist-advanced-analytics-ibm-india-pvt-limited-bengaluru-bangalore-3-to-7-years-070921901677?src=jobsearchDesk&sid=1631543662342285&xp=8&px=1',\n",
       " 'https://www.naukri.com/job-listings-senior-data-scientist-walmart-labs-bangalore-bengaluru-6-to-10-years-090921501063?src=jobsearchDesk&sid=1631543662342285&xp=9&px=1',\n",
       " 'https://www.naukri.com/job-listings-senior-data-scientist-airbnb-bangalore-bengaluru-7-to-12-years-080921500017?src=jobsearchDesk&sid=1631543662342285&xp=10&px=1']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "href2=href1[0:10]\n",
    "href2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in href2:\n",
    "    driver.get(i)\n",
    "    job3=driver.find_elements_by_xpath(\"//div[@class='dang-inner-html']\")\n",
    "    for j in job3:\n",
    "        dis=j.text.replace('\\n', '')\n",
    "    if dis==np.nan:\n",
    "        dis.fillna(method='ffill')\n",
    "    else:\n",
    "        full_job_description.append(dis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Minumum 3 years of experience in Data Science/Machine learningLocation : PAN INDIAExp : 3 - 7 YearsMinimum 3 year of experience in being Applied Machine Learning Engineer roleResearch, develop, and implement prediction, optimization, and analytics tools.Document and communicate methodology and results to technical and non-technical audiencesGuide and implement best practices of curated data and evaluate ML models on large-scale dataLead design and implementation of Machine Learning algorithms, combining with rule-based optimization to deliver significant improvement inproduct metricsWrite production ready high quality, maintainable and scalable code.Design and analyze metrics to verify model and algorithm effectiveness.Experience with data analysis languages such as Python or ScalaExperience with Machine Learning tools (Azure ML, SageMaker, TensorFlow, Kubernetes, etc.)Experience with Machine Learning Languages (R, Python, .Net Core, etc.)',\n",
       " 'Minumum 3 years of experience in Data Science/Machine learningLocation : PAN INDIAExp : 3 - 7 YearsMinimum 3 year of experience in being Applied Machine Learning Engineer roleResearch, develop, and implement prediction, optimization, and analytics tools.Document and communicate methodology and results to technical and non-technical audiencesGuide and implement best practices of curated data and evaluate ML models on large-scale dataLead design and implementation of Machine Learning algorithms, combining with rule-based optimization to deliver significant improvement inproduct metricsWrite production ready high quality, maintainable and scalable code.Design and analyze metrics to verify model and algorithm effectiveness.Experience with data analysis languages such as Python or ScalaExperience with Machine Learning tools (Azure ML, SageMaker, TensorFlow, Kubernetes, etc.)Experience with Machine Learning Languages (R, Python, .Net Core, etc.)',\n",
       " 'Use predictive modeling to increase and optimize customer experiences, revenue generation, campaign optimization and other business outcomesWork with product management to develop data use cases and embed predictive models in workflows on resource constrained platforms and cloud enabled.Selecting features, building and optimizing classifiers using machine learning and deep learning techniquesCollaborates with Data Engineers to enhance data collection and ingestion/curation techniques to include information that is relevant for building analytic systemsProcessing, cleansing, and verifying the integrity of data used for analysisDevelop processes and tools to monitor and analyze model performance and data accuracy. Life cycle management of predictive models.Adherence to compliance procedures in accordance with regulatory standards, requirements, and policies. Managing and designing the reporting environment, including data sources security, and metadata.Job Qualifications:Master s degree or PhD in Computer Science, Information management, Statistics or related field, with 3 to 5 years of experience in the Consumer or Healthcare industry manipulating data sets and building predictive models with focus on product developmentExperience in statistical modelling, machine learning, data mining, unstructured data analytics and natural language processing. Sound understanding of - Bayesian Modelling, Classification Models, Cluster Analysis, Neural Network, Nonparametric Methods, Multivariate Statistics, etc.Strong hands on knowledge of ML techniques like regression algorithms, K-NN, Na ve Bayes, SVM and ensemble techniques like Random forest, AdaBoost etcHaving strong knowledge in unsupervised learning algorithms using Neural networks and Deep-LearningStrong knowledge in Data Wrangling and Exploration techniques to identify the patterns, trends and outliners.Deep knowledge and practical experience with data science toolkits, such as NumPy, Pandas, scikit-learn or equivalentExperience with data visualization tools, such as QlikView, Matplotlib, seaborn or equivalent tools.Proficiency in using query languages, such as SQL, PL/SQLHands on experience in the one or more databases like Hadoop, AWS Redshift, Snowflake etc.Good applied statistics skills, such as distributions, statistical testing, regression, etc.Good ETL scripting and programming skills, such as Python, R or Scala to integrate developed solution into the proposition.A team player capable of working and integrating across cross-functional team for implementing project requirements. Experience in technical requirements gathering and documentation.Ability to work effectively and independently in a fast-paced global collaborative agile team environment with tight deadlinesA flexible, pragmatic and collaborative team player with innate ability to engage with stakeholders at all levels in the organization.A self-starter with high levels of drive, energy, resilience and a desire for professional excellence with a passion for data and data science',\n",
       " 'A day in the Life of Data Scientist at Brillio, you will:• Partner closely with project managers to deconstruct business problems of the client, develop data models and algorithms that deliver meaningful insights• Take ownership of whole end-to-end predictive modeling projects - from data processing, training, optimization to real-time monitoring and maintenance• Develop solutions to data driven problems, and communicate relevant insights to stakeholders through storyboards/presentations• Stay abreast with current technical and industry development and constantly strive to devise innovative statistical models for data analysis• Actively participate in external forums and industry conclavesFor you to be successful, you must:• Create value by meeting needs of stakeholders and delivering high-quality results• Open and flexible to accommodate and implement new ideas, understand business complexities, nurture innovation and challenge the status quo persistently• Strive to be subject matter expert in chosen area of specialty through continuous learning• Have an eye for detail to ensure accurate conclusions in data analysis and presentations. Disseminate knowledge and share own experiential learning with othersYou’ll bring this to the table:• Critical Thinking: ability to work in ambiguous situations with unstructured problems• Strong analytical skills with the ability to collect, organize, review significant amounts of information• Experience using statistical computer language Python to manipulate data and draw insights from large data sets.• Working knowledge in basic statistical concepts such as properties of distributions, statistical tests and their proper usage• Expertise in some of the advanced machine learning techniques such as Clustering, Regression/Classification, Time Series Analysis, Network Analysis, Popular Deep Learning architectures and theory, simulation, scenario analysis• Clear, professional written and verbal communication skills, ability to easily communicate complex ideas• Experience with any distributed data/computing tools: Map/Reduce, Hadoop, Hive, Spark, etc.• Experience with machine learning on Cloud.',\n",
       " 'ResponsibilitiesApply state of the art in the relevant research domains to make significant contributions to the feature roadmap of the ShareChat app in the aforementioned areas.Apply expert coding skills to develop scalable product features in partnership with other engineers on app and infrastructure teamsApply best practices in big data processing to build feature stores, data pipelines, and model inference services that can deal with massive scale.Adapt deep learning algorithms to best exploit modern parallel environments (e.g. distributed clusters, GPUs). In the case of on-device applications, tune network architectures to efficiently run on low to medium end smartphones.QualificationsBTech, MS degree or Ph.D degree in Computer Science or a related disciplineExperience in deploying ML models with frameworks like Tensorflow, PyTorch, MXNet, Caffe, Torch, etc on Android and iOS devicesExcellent coding skills in C/C++ and JavaKnowledge of evolving and recent technologies in Android, IOS app development and different mobile compute and memory resources and sensorsAbility to build basic Android/iOS apps using NDK for Audio-Video capture and processing pipeline with basic UI features is neededExperience with multi threaded implementations utilizing computer units like multi core CPU, GPU, NPU, DSP and media encode/decide accelerators is a huge plus',\n",
       " \"Must Have skill sets:Excellent knowledge of various statistical / Machine Learning / Deep Learning algorithms such as Feature Engineering/selection, Time series, Regression, Classification, Clustering, Recommendation Engine, Anomaly Detection, NLP, Reinforcement Learning etc.)4 to 8 years of hands-on expertise in developing data science models by applying above mentioned algorithms on structured / text data, using R / PythonProficient in writing optimized query using any one of the DB query language (Hive/Impala/SQL/MongoDB etc.). Knowledge of big data is essentialGood to Have skill sets:Visualization using any one of the technologies (Tableau, PowerBI, RShiny, matplotlib, ggplot etc.). In case of lack of skills, eagerness to learn is mustInsight Generation and Story telling to end consumersExperience across end to end data science project life cycle (use case framing, data collection, data exploration, design of experiments, model development, selection and deployment, post production support)Self-motivated to learn different techniques / technologies, as per the project's need and go extra mile to bring customer delightEducational Qualification:Any of the following:• Bachelors in Engineering / MCA• Masters in Data Science/ Computer Applications/ Statistics/ Mathematics/ Economics/ Ops Research/ Other quantitative disciplines• MBAJob Responsibilities:Own and execute end to end delivery of one or more than one data science model development, as per requirement provided by project/product managerUnderstand business requirements from Product Managers/Business UsersExtract data from multiple data sources using Hadoop / SQLDevelop, Validate and Operationalize predictive models using appropriate variables and ML/deep learning techniquesPerform ad-hoc deep dive analysis and generate actionable insightsCreate technical documentation and provide post-production support for a time-bound periodCommunicate the results to technical as well as business stakeholders across different hierarchies\",\n",
       " \"Must Have skill sets:Excellent knowledge of various statistical / Machine Learning / Deep Learning algorithms such as Feature Engineering/selection, Time series, Regression, Classification, Clustering, Recommendation Engine, Anomaly Detection, NLP, Reinforcement Learning etc.)4 to 8 years of hands-on expertise in developing data science models by applying above mentioned algorithms on structured / text data, using R / PythonProficient in writing optimized query using any one of the DB query language (Hive/Impala/SQL/MongoDB etc.). Knowledge of big data is essentialGood to Have skill sets:Visualization using any one of the technologies (Tableau, PowerBI, RShiny, matplotlib, ggplot etc.). In case of lack of skills, eagerness to learn is mustInsight Generation and Story telling to end consumersExperience across end to end data science project life cycle (use case framing, data collection, data exploration, design of experiments, model development, selection and deployment, post production support)Self-motivated to learn different techniques / technologies, as per the project's need and go extra mile to bring customer delightEducational Qualification:Any of the following:• Bachelors in Engineering / MCA• Masters in Data Science/ Computer Applications/ Statistics/ Mathematics/ Economics/ Ops Research/ Other quantitative disciplines• MBAJob Responsibilities:Own and execute end to end delivery of one or more than one data science model development, as per requirement provided by project/product managerUnderstand business requirements from Product Managers/Business UsersExtract data from multiple data sources using Hadoop / SQLDevelop, Validate and Operationalize predictive models using appropriate variables and ML/deep learning techniquesPerform ad-hoc deep dive analysis and generate actionable insightsCreate technical documentation and provide post-production support for a time-bound periodCommunicate the results to technical as well as business stakeholders across different hierarchies\",\n",
       " \"Must Have skill sets:Excellent knowledge of various statistical / Machine Learning / Deep Learning algorithms such as Feature Engineering/selection, Time series, Regression, Classification, Clustering, Recommendation Engine, Anomaly Detection, NLP, Reinforcement Learning etc.)4 to 8 years of hands-on expertise in developing data science models by applying above mentioned algorithms on structured / text data, using R / PythonProficient in writing optimized query using any one of the DB query language (Hive/Impala/SQL/MongoDB etc.). Knowledge of big data is essentialGood to Have skill sets:Visualization using any one of the technologies (Tableau, PowerBI, RShiny, matplotlib, ggplot etc.). In case of lack of skills, eagerness to learn is mustInsight Generation and Story telling to end consumersExperience across end to end data science project life cycle (use case framing, data collection, data exploration, design of experiments, model development, selection and deployment, post production support)Self-motivated to learn different techniques / technologies, as per the project's need and go extra mile to bring customer delightEducational Qualification:Any of the following:• Bachelors in Engineering / MCA• Masters in Data Science/ Computer Applications/ Statistics/ Mathematics/ Economics/ Ops Research/ Other quantitative disciplines• MBAJob Responsibilities:Own and execute end to end delivery of one or more than one data science model development, as per requirement provided by project/product managerUnderstand business requirements from Product Managers/Business UsersExtract data from multiple data sources using Hadoop / SQLDevelop, Validate and Operationalize predictive models using appropriate variables and ML/deep learning techniquesPerform ad-hoc deep dive analysis and generate actionable insightsCreate technical documentation and provide post-production support for a time-bound periodCommunicate the results to technical as well as business stakeholders across different hierarchies\",\n",
       " 'As a Senior Data Scientist for Walmart, you ll have the opportunity to:Drive data-derived insights across a wide range of divisions by developing advanced statistical models, machine learning algorithms and computational algorithms based on business initiativesDirect the gathering of data, assessing data validity and synthesizing data into large analytics datasets to support project goalsUtilize big data analytics and advanced data science techniques to identify trends, patterns, and discrepancies in data. Determine additional data needed to support insightsBuild and train statistical models and machine learning algorithmsApply your semantic, natural language processing and understanding expertise where requiredUse deep learning and image recognition project goalsComputer Vision will be an important focus area for this roleProductionize the models and make those available at scaleBuild and maintain end to end Machine Learning pipelinesBe comfortable with ambiguity and uncertainty and the eagerness to change the world in a huge way by being a self-motivated learner and builderCommunicate recommendations to business partners and influencing future plans based on insightsYour ResponsibilityPlay a key role to solve complex problems, pivotal to Walmart s business and drive actionable insights from petabytes of dataUtilize product mindset to build, scale and deploy holistic data science products after successful prototypingDemonstrate incremental solution approach with agile and flexible ability to overcome practical problemsPartner with senior team members to assess customer needs and define business questionsClearly articulate and present recommendations to business partners, and influence future plans based on insightsWork with customer centric mindset to deliver high quality business driven analytic solutionDrive innovation in approach, method, practices, process, outcome, delivery, or any component of end-to-end problem solvingDemonstrates up-to-date expertise and applies this to the development, execution, and improvement of action plansPreferred QualificationsBachelors degree in Statistics, Mathematics, Computer Science or a related field and 8 years experience in an analytics/DS related field, or,Masters degree in Statistics, Mathematics, Computer Science or a related field and 6 years experience in an analytics/DS related field.High proficiency in data mining, modeling, validation and insight generation.Excellent working knowledge of statistics, mathematics, machine learning, data mining, deep learningHigh proficiency in coding including Python and SQLExperience with databases (for example, DB2, Oracle, SQL Server)Experience with Big Data technologies such as Pig, Hive and/or SparkAbility to work with large data sets. Has sound understanding of big data technology stackUnderstanding of cloud computing platforms and large-scale databasesProven ability to collaborate and work in teamsExcellent with communications and stakeholder engagementData science publications in recognized platforms/journalsProven ability to work in agile mode on data science sprint projects',\n",
       " 'Responsibilities include:Defining and evaluating key metrics and understanding what moves them and whyOwnership of conceptualizing, developing, and maintaining dashboards and visualizationsInvestigating evolving fraud trends to extract patterns, identify root causes and propose actionable solutionsCommunicating analyses and recommendations to cross functional stakeholders for decision makingEmpowering the team to answer data questions quickly and easily by building high-quality ground truth data setsHere are example traits we value:Professional industry experience in a quantitative analysis role (7+ years preferred)Comfortable in SQL and some experience with a programming language (Python or R a plus)Ability to communicate clearly and effectively to cross functional partners of varying technical levelsAbility to define relevant metrics that can guide and influence stakeholders to the appropriate and accurate insightsExperience or willingness to learn tools to create data pipelines using AirflowBuilding clear and easy to understand dashboards (Tableau) and presentations']"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_job_description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20 20 20 10\n"
     ]
    }
   ],
   "source": [
    "print(len(job_titles),len(company_names),len(location_list),len(full_job_description))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "jobs=pd.DataFrame({})\n",
    "jobs['job_titles']=job_titles[:10]\n",
    "jobs['company_names']=company_names[:10]\n",
    "jobs['location_list']=location_list[:10]\n",
    "jobs['full_job_description']=full_job_description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>job_titles</th>\n",
       "      <th>company_names</th>\n",
       "      <th>location_list</th>\n",
       "      <th>full_job_description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>Hiring For Data Scientist</td>\n",
       "      <td>Tata Consultancy Services Ltd.</td>\n",
       "      <td>Chennai, Bangalore/Bengaluru, Mumbai (All Areas)</td>\n",
       "      <td>Minumum 3 years of experience in Data Science/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>Lead Data Scientist BFSI</td>\n",
       "      <td>IBM India Pvt. Limited</td>\n",
       "      <td>Bengaluru/Bangalore</td>\n",
       "      <td>Minumum 3 years of experience in Data Science/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>Associate Data Scientist</td>\n",
       "      <td>Philips India Limited</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Use predictive modeling to increase and optimi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Brillio</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>A day in the Life of Data Scientist at Brillio...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>Data Scientist - I / II</td>\n",
       "      <td>Sharechat</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>ResponsibilitiesApply state of the art in the ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Allegis Services India Pvt. Ltd.</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Must Have skill sets:Excellent knowledge of va...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Allegis Services India Pvt. Ltd.</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Must Have skill sets:Excellent knowledge of va...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>Data Scientist: Advanced Analytics</td>\n",
       "      <td>IBM India Pvt. Limited</td>\n",
       "      <td>Bengaluru/Bangalore</td>\n",
       "      <td>Must Have skill sets:Excellent knowledge of va...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>Senior Data Scientist</td>\n",
       "      <td>Walmart Labs</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>As a Senior Data Scientist for Walmart, you ll...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>Senior Data Scientist</td>\n",
       "      <td>Airbnb</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Responsibilities include:Defining and evaluati...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           job_titles                     company_names  \\\n",
       "0           Hiring For Data Scientist    Tata Consultancy Services Ltd.   \n",
       "1            Lead Data Scientist BFSI            IBM India Pvt. Limited   \n",
       "2            Associate Data Scientist             Philips India Limited   \n",
       "3                      Data Scientist                           Brillio   \n",
       "4             Data Scientist - I / II                         Sharechat   \n",
       "5                      Data Scientist  Allegis Services India Pvt. Ltd.   \n",
       "6                      Data Scientist  Allegis Services India Pvt. Ltd.   \n",
       "7  Data Scientist: Advanced Analytics            IBM India Pvt. Limited   \n",
       "8               Senior Data Scientist                      Walmart Labs   \n",
       "9               Senior Data Scientist                            Airbnb   \n",
       "\n",
       "                                      location_list  \\\n",
       "0  Chennai, Bangalore/Bengaluru, Mumbai (All Areas)   \n",
       "1                               Bengaluru/Bangalore   \n",
       "2                               Bangalore/Bengaluru   \n",
       "3                               Bangalore/Bengaluru   \n",
       "4                               Bangalore/Bengaluru   \n",
       "5                               Bangalore/Bengaluru   \n",
       "6                               Bangalore/Bengaluru   \n",
       "7                               Bengaluru/Bangalore   \n",
       "8                               Bangalore/Bengaluru   \n",
       "9                               Bangalore/Bengaluru   \n",
       "\n",
       "                                full_job_description  \n",
       "0  Minumum 3 years of experience in Data Science/...  \n",
       "1  Minumum 3 years of experience in Data Science/...  \n",
       "2  Use predictive modeling to increase and optimi...  \n",
       "3  A day in the Life of Data Scientist at Brillio...  \n",
       "4  ResponsibilitiesApply state of the art in the ...  \n",
       "5  Must Have skill sets:Excellent knowledge of va...  \n",
       "6  Must Have skill sets:Excellent knowledge of va...  \n",
       "7  Must Have skill sets:Excellent knowledge of va...  \n",
       "8  As a Senior Data Scientist for Walmart, you ll...  \n",
       "9  Responsibilities include:Defining and evaluati...  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jobs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q3: In this question you have to scrape data using the filters available on the webpage as shown below:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You have to use the location and salary filter. You have to scrape data for “Data Scientist” designation for first 10 job results. You have to scrape the job-title, job-location, company_name, experience_required. The location filter to be used is “Delhi/NCR” The salary filter to be used is “3-6” lakhs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import selenium\n",
    "import pandas as pd\n",
    "from selenium import webdriver\n",
    "import time\n",
    "# Opening Browsers in Incognito using Options\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "chrome_options = Options()\n",
    "chrome_options.add_argument('--incognito')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function opens the naukri home page and searches for 'Data Analyst' and 'Bangalore'\n",
    "\n",
    "def naukri(url):\n",
    "    driver=webdriver.Chrome(r\"C:\\Users\\dheerajkumar_pittala\\DataPy\\Browserdrivers\\chromedriver.exe\")\n",
    "    # 1. first get the webpage https://www.naukri.com/\n",
    "    driver.get(url)\n",
    "    \n",
    "    # 2. Enter “Data Analyst” in “Skill,Designations,Companies” field \n",
    "    job_search=driver.find_element_by_id('qsb-keyword-sugg')\n",
    "    job_search.send_keys(\"Data Scientist\")\n",
    "    \n",
    "    # and enter “Bangalore” in “enter the location” field \n",
    "    location_search=driver.find_element_by_xpath(\"//input[@id='qsb-location-sugg']\")\n",
    "    location_search.send_keys(\"Delhi/NCR\")\n",
    " \n",
    "    # 3. Then click the search button\n",
    "    search_buton=driver.find_element_by_xpath(\"//div[@class='search-btn']/button\")\n",
    "    search_buton.click()\n",
    "    time.sleep(5)\n",
    "\n",
    "    # 4. Then scrape the data for the first 10 jobs results you get.\n",
    "    job_titles=[]\n",
    "    title_tags=driver.find_elements_by_xpath(\"//a[@class='title fw500 ellipsis']\")[:10]\n",
    "    for i in title_tags:\n",
    "        job_titles.append(i.text)\n",
    "    \n",
    "    company_names=[]\n",
    "    company_tags=driver.find_elements_by_xpath(\"//a[@class='subTitle ellipsis fleft']\")[:10]\n",
    "    for i in company_tags:\n",
    "        company_names.append(i.text)\n",
    "        \n",
    "    experience_list=[]\n",
    "    exp_tags=driver.find_elements_by_xpath(\"//li[@class='fleft grey-text br2 placeHolderLi experience']/span\")[:10]\n",
    "    for i in exp_tags:\n",
    "        experience_list.append(i.text)\n",
    "        \n",
    "    salary_list=[]\n",
    "    sal_tags=driver.find_elements_by_xpath(\"//li[@class='fleft grey-text br2 placeHolderLi salary']/span\")[:10]\n",
    "    for i in sal_tags:\n",
    "        salary_list.append(i.text)\n",
    "        \n",
    "    locations_list=[]\n",
    "    loc_tags=driver.find_elements_by_xpath(\"//li[@class='fleft grey-text br2 placeHolderLi location']/span\")[:10]\n",
    "    for i in loc_tags:\n",
    "        locations_list.append(i.text)\n",
    "        \n",
    "    jobs=pd.DataFrame({})\n",
    "    jobs['job_titles']=job_titles\n",
    "    jobs['company_names']=company_names\n",
    "    jobs['locations_list']=locations_list\n",
    "    jobs['experience_list']=experience_list\n",
    "    jobs['salary_list']=salary_list\n",
    "    \n",
    "    driver.close()\n",
    "    return(jobs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>job_titles</th>\n",
       "      <th>company_names</th>\n",
       "      <th>locations_list</th>\n",
       "      <th>experience_list</th>\n",
       "      <th>salary_list</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>Senior Data Scientist ( m / f / d )</td>\n",
       "      <td>Adidas Group</td>\n",
       "      <td>Gurgaon/Gurugram</td>\n",
       "      <td>5-10 Yrs</td>\n",
       "      <td>Not disclosed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>Hiring For Manager and Sr. Manager | Data Scie...</td>\n",
       "      <td>Vision Beyond Resources India Private Limited</td>\n",
       "      <td>Noida, Mumbai, New Delhi, Gurgaon/Gurugram, Ba...</td>\n",
       "      <td>8-13 Yrs</td>\n",
       "      <td>20,00,000 - 35,00,000 PA.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>Data Scientist / Data Analyst / Business Analy...</td>\n",
       "      <td>GABA Consultancy services</td>\n",
       "      <td>Ghaziabad, Faridabad, Delhi / NCR</td>\n",
       "      <td>0-0 Yrs</td>\n",
       "      <td>2,25,000 - 4,75,000 PA.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>Associate Vice President - Data Scientist - II...</td>\n",
       "      <td>Huquo Consulting Pvt. Ltd</td>\n",
       "      <td>Gurgaon/Gurugram</td>\n",
       "      <td>8-12 Yrs</td>\n",
       "      <td>Not disclosed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>Sr Data Scientist</td>\n",
       "      <td>Superior Group</td>\n",
       "      <td>New Delhi</td>\n",
       "      <td>6-11 Yrs</td>\n",
       "      <td>Not disclosed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>Sr. Data Scientist/Data Scientist</td>\n",
       "      <td>Pentair Water India Pvt Ltd</td>\n",
       "      <td>Noida</td>\n",
       "      <td>8-12 Yrs</td>\n",
       "      <td>15,00,000 - 25,00,000 PA.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>Data Scientist- Senior Business Analyst/Lead A...</td>\n",
       "      <td>Evalueserve.com Pvt. Ltd</td>\n",
       "      <td>Gurgaon/Gurugram, Bangalore/Bengaluru</td>\n",
       "      <td>2-7 Yrs</td>\n",
       "      <td>Not disclosed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>Lead Data Scientist</td>\n",
       "      <td>Monotype Imaging</td>\n",
       "      <td>Noida</td>\n",
       "      <td>8-10 Yrs</td>\n",
       "      <td>Not disclosed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>Lead Data Scientist</td>\n",
       "      <td>Monotype Imaging</td>\n",
       "      <td>Noida</td>\n",
       "      <td>8-10 Yrs</td>\n",
       "      <td>Not disclosed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>Co-Founder &amp; Principal Data Scientist/Senior S...</td>\n",
       "      <td>Benovymed Healthcare</td>\n",
       "      <td>Gurgaon/Gurugram, Delhi / NCR</td>\n",
       "      <td>2-7 Yrs</td>\n",
       "      <td>Not disclosed</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          job_titles  \\\n",
       "0                Senior Data Scientist ( m / f / d )   \n",
       "1  Hiring For Manager and Sr. Manager | Data Scie...   \n",
       "2  Data Scientist / Data Analyst / Business Analy...   \n",
       "3  Associate Vice President - Data Scientist - II...   \n",
       "4                                  Sr Data Scientist   \n",
       "5                  Sr. Data Scientist/Data Scientist   \n",
       "6  Data Scientist- Senior Business Analyst/Lead A...   \n",
       "7                                Lead Data Scientist   \n",
       "8                                Lead Data Scientist   \n",
       "9  Co-Founder & Principal Data Scientist/Senior S...   \n",
       "\n",
       "                                   company_names  \\\n",
       "0                                   Adidas Group   \n",
       "1  Vision Beyond Resources India Private Limited   \n",
       "2                      GABA Consultancy services   \n",
       "3                      Huquo Consulting Pvt. Ltd   \n",
       "4                                 Superior Group   \n",
       "5                    Pentair Water India Pvt Ltd   \n",
       "6                       Evalueserve.com Pvt. Ltd   \n",
       "7                               Monotype Imaging   \n",
       "8                               Monotype Imaging   \n",
       "9                           Benovymed Healthcare   \n",
       "\n",
       "                                      locations_list experience_list  \\\n",
       "0                                   Gurgaon/Gurugram        5-10 Yrs   \n",
       "1  Noida, Mumbai, New Delhi, Gurgaon/Gurugram, Ba...        8-13 Yrs   \n",
       "2                  Ghaziabad, Faridabad, Delhi / NCR         0-0 Yrs   \n",
       "3                                   Gurgaon/Gurugram        8-12 Yrs   \n",
       "4                                          New Delhi        6-11 Yrs   \n",
       "5                                              Noida        8-12 Yrs   \n",
       "6              Gurgaon/Gurugram, Bangalore/Bengaluru         2-7 Yrs   \n",
       "7                                              Noida        8-10 Yrs   \n",
       "8                                              Noida        8-10 Yrs   \n",
       "9                      Gurgaon/Gurugram, Delhi / NCR         2-7 Yrs   \n",
       "\n",
       "                 salary_list  \n",
       "0              Not disclosed  \n",
       "1  20,00,000 - 35,00,000 PA.  \n",
       "2    2,25,000 - 4,75,000 PA.  \n",
       "3              Not disclosed  \n",
       "4              Not disclosed  \n",
       "5  15,00,000 - 25,00,000 PA.  \n",
       "6              Not disclosed  \n",
       "7              Not disclosed  \n",
       "8              Not disclosed  \n",
       "9              Not disclosed  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=naukri('https://www.naukri.com/')\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q4: Write a python program to scrape data for first 10 job results for Data scientist Designation in Noida location. You have to scrape company_name, No. of days ago when job was posted, Rating of the company. [Glassdoor]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: selenium in c:\\users\\dheerajkumar_pittala\\appdata\\local\\continuum\\anaconda3\\lib\\site-packages (3.141.0)\n",
      "Requirement already satisfied: urllib3 in c:\\users\\dheerajkumar_pittala\\appdata\\local\\continuum\\anaconda3\\lib\\site-packages (from selenium) (1.24.2)\n"
     ]
    }
   ],
   "source": [
    "!pip install selenium\n",
    "\n",
    "import selenium\n",
    "import pandas as pd\n",
    "from selenium import webdriver\n",
    "import time\n",
    "# Opening Browsers in Incognito using Options\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "chrome_options = Options()\n",
    "chrome_options.add_argument('--incognito')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#let's connect to the webdriver\n",
    "\n",
    "driver= webdriver.Chrome(r'C:\\Users\\dheerajkumar_pittala\\DataPy\\Browserdrivers\\chromedriver.exe')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.get('https://www.glassdoor.co.in/index.htm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "from time import sleep\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.common.exceptions import TimeoutException\n",
    "from selenium.common.exceptions import StaleElementReferenceException\n",
    "from selenium.common.exceptions import NoSuchElementException\n",
    "from selenium.webdriver.common.by import By"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "CHROMEDRIVER_PATH = './chromedriver'\n",
    "WINDOW_SIZE = \"1920,1080\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comman function for init driver\n",
    "def init_driver(url):\n",
    "    driver = webdriver.Chrome(executable_path=CHROMEDRIVER_PATH)\n",
    "    driver.maximize_window()\n",
    "    driver.get(url)\n",
    "    return driver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def wait_for_page_load(xpath_url):\n",
    "    try:\n",
    "        element_present = EC.presence_of_element_located((By.XPATH, xpath_url))\n",
    "        WebDriverWait(driver, 5).until(element_present)\n",
    "    except TimeoutException:\n",
    "        print(\"Timed out waiting for page to load\")\n",
    "    except NoSuchElementException:\n",
    "        print(\"Element not found\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "email = 'imironman@mailinator.com'\n",
    "password = 'rBrD33sjd7SamBv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "#let's connect to the webdriver\n",
    "\n",
    "driver= webdriver.Chrome(r'C:\\Users\\dheerajkumar_pittala\\DataPy\\Browserdrivers\\chromedriver.exe')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# init driver\n",
    "driver.get('https://www.glassdoor.co.in/index.htm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we have to singin first before fetching jobs\n",
    "\n",
    "wait_for_page_load('//article[@id=\"MainCol\"]//li')    \n",
    "\n",
    "# click on sign in \n",
    "driver.find_elements_by_xpath('//button[contains(@class,\"LockedHomeHeaderStyles__signInButton\")]')[1].click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pasting email and password\n",
    "driver.find_element_by_xpath('//form[@name=\"emailSignInForm\"]//input[@id=\"userEmail\"]').send_keys(email)\n",
    "driver.find_element_by_xpath('//form[@name=\"emailSignInForm\"]//input[@id=\"userPassword\"]').send_keys(password)\n",
    "\n",
    "# click on sing in \n",
    "driver.find_element_by_xpath('//form[@name=\"emailSignInForm\"]//button[@type=\"submit\"]').click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add data to keyword field \n",
    "wait_for_page_load('//input[@id=\"sc.keyword\"]')  \n",
    "\n",
    "driver.find_element_by_xpath('//input[@id=\"sc.keyword\"]').send_keys('Data Scientist')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add data to location filed\n",
    "driver.find_element_by_xpath('//input[@id=\"sc.location\"]').send_keys(Keys.CONTROL + \"a\")\n",
    "driver.find_element_by_xpath('//input[@id=\"sc.location\"]').send_keys(Keys.DELETE)\n",
    "driver.find_element_by_xpath('//input[@id=\"sc.location\"]').send_keys('Noida')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hit search \n",
    "driver.find_element_by_xpath('//button[@type=\"submit\" and contains(@class,\"search__SearchStyles__newSearchButton\")]').click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ago_posted</th>\n",
       "      <th>company_name</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>19d</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>30d+</td>\n",
       "      <td>Associate Data Scientist</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>30d+</td>\n",
       "      <td>Data Scientist Intern</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td></td>\n",
       "      <td>Data Analytics part time job/internship at Noida</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>6d</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>30d+</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>5d</td>\n",
       "      <td>Management Trainee – Data Science</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>5d</td>\n",
       "      <td>Analyst – Data Science</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>30d+</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>30d+</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  ago_posted                                      company_name rating\n",
       "0        19d                                    Data Scientist       \n",
       "1       30d+                          Associate Data Scientist       \n",
       "2       30d+                             Data Scientist Intern       \n",
       "3             Data Analytics part time job/internship at Noida       \n",
       "4         6d                                    Data Scientist       \n",
       "5       30d+                                    Data Scientist       \n",
       "6         5d                 Management Trainee – Data Science       \n",
       "7         5d                            Analyst – Data Science       \n",
       "8       30d+                                    Data Scientist       \n",
       "9       30d+                                    Data Scientist       "
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# wait for page load\n",
    "wait_for_page_load('//article[@id=\"MainCol\"]//li')    \n",
    "\n",
    "# finding top 10 boxes \n",
    "all_box = driver.find_elements_by_xpath('//article[@id=\"MainCol\"]//li')[:10]\n",
    "    \n",
    "final_data = []\n",
    "\n",
    "# Ittrating over box to find details\n",
    "for one_box in all_box:\n",
    "    ago_posted = one_box.find_element_by_xpath('.//div[@data-test=\"job-age\"]').text\n",
    "    company_name = one_box.find_element_by_xpath('.//a[@data-test=\"job-link\"]').text\n",
    "    try:\n",
    "        \n",
    "        rating = one_box.find_element_by_xpath('.//span[contains(@class,\"css-19pjha7\")]').text \n",
    "    except:\n",
    "        rating = ''\n",
    "    \n",
    "    \n",
    "    final_data.append({\n",
    "        'ago_posted':ago_posted,\n",
    "        'company_name':company_name,\n",
    "        'rating':rating,\n",
    "    })\n",
    "    \n",
    "job_data = pd.DataFrame(final_data)\n",
    "job_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q5: Write a python program to scrape the salary data for Data Scientist designation in Noida location. You have to scrape Company name, Number of salaries, Average salary, Min salary, Max Salary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "from time import sleep\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.common.exceptions import TimeoutException\n",
    "from selenium.common.exceptions import StaleElementReferenceException\n",
    "from selenium.common.exceptions import NoSuchElementException\n",
    "from selenium.webdriver.common.by import By"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "CHROMEDRIVER_PATH = './chromedriver'\n",
    "WINDOW_SIZE = \"1920,1080\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comman function for init driver\n",
    "def init_driver(url):\n",
    "    driver = webdriver.Chrome(executable_path=CHROMEDRIVER_PATH)\n",
    "    driver.maximize_window()\n",
    "    driver.get(url)\n",
    "    return driver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def wait_for_page_load(xpath_url):\n",
    "    try:\n",
    "        element_present = EC.presence_of_element_located((By.XPATH, xpath_url))\n",
    "        WebDriverWait(driver, 5).until(element_present)\n",
    "    except TimeoutException:\n",
    "        print(\"Timed out waiting for page to load\")\n",
    "    except NoSuchElementException:\n",
    "        print(\"Element not found\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "email = 'imironman@mailinator.com'\n",
    "password = 'rBrD33sjd7SamBv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "#let's connect to the webdriver\n",
    "\n",
    "driver= webdriver.Chrome(r'C:\\Users\\dheerajkumar_pittala\\DataPy\\Browserdrivers\\chromedriver.exe')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "#going to salary page\n",
    "driver.get('https://www.glassdoor.co.in/Salaries/index.htm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add data to keyword field \n",
    "driver.find_element_by_xpath('//input[@id=\"KeywordSearch\"]').send_keys('Data Scientist')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add data to location filed\n",
    "driver.find_element_by_xpath('//input[@id=\"LocationSearch\"]').clear()\n",
    "driver.find_element_by_xpath('//input[@id=\"LocationSearch\"]').send_keys('Noida')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hit search \n",
    "driver.find_element_by_xpath('//button[@id=\"HeroSearchButton\"]').click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Timed out waiting for page to load\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>min_salary</th>\n",
       "      <th>max_salary</th>\n",
       "      <th>average_salary</th>\n",
       "      <th>company_name</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>₹4L</td>\n",
       "      <td>₹13L</td>\n",
       "      <td>₹6,28,021</td>\n",
       "      <td>Tata Consultancy Services</td>\n",
       "      <td>3.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>₹1L</td>\n",
       "      <td>₹28L</td>\n",
       "      <td>₹9,08,246</td>\n",
       "      <td>IBM</td>\n",
       "      <td>3.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>₹6L</td>\n",
       "      <td>₹23L</td>\n",
       "      <td>₹11,93,390</td>\n",
       "      <td>Accenture</td>\n",
       "      <td>4.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>₹5L</td>\n",
       "      <td>₹1Cr</td>\n",
       "      <td>₹12,49,716</td>\n",
       "      <td>Delhivery</td>\n",
       "      <td>3.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>₹4L</td>\n",
       "      <td>₹17L</td>\n",
       "      <td>₹7,58,335</td>\n",
       "      <td>Ericsson-Worldwide</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>₹8L</td>\n",
       "      <td>₹16L</td>\n",
       "      <td>₹12,80,000</td>\n",
       "      <td>UnitedHealth Group</td>\n",
       "      <td>3.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>₹8L</td>\n",
       "      <td>₹20L</td>\n",
       "      <td>₹12,70,000</td>\n",
       "      <td>Optum</td>\n",
       "      <td>3.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>₹10L</td>\n",
       "      <td>₹18L</td>\n",
       "      <td>₹14,55,430</td>\n",
       "      <td>Optum Global Solutions</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>₹5L</td>\n",
       "      <td>₹15L</td>\n",
       "      <td>₹8,86,064</td>\n",
       "      <td>Valiance Solutions</td>\n",
       "      <td>4.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>₹6L</td>\n",
       "      <td>₹16L</td>\n",
       "      <td>₹11,10,000</td>\n",
       "      <td>EXL Service</td>\n",
       "      <td>3.6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  min_salary max_salary average_salary               company_name rating\n",
       "0        ₹4L       ₹13L      ₹6,28,021  Tata Consultancy Services    3.9\n",
       "1        ₹1L       ₹28L      ₹9,08,246                        IBM    3.9\n",
       "2        ₹6L       ₹23L     ₹11,93,390                  Accenture    4.1\n",
       "3        ₹5L       ₹1Cr     ₹12,49,716                  Delhivery    3.7\n",
       "4        ₹4L       ₹17L      ₹7,58,335         Ericsson-Worldwide      4\n",
       "5        ₹8L       ₹16L     ₹12,80,000         UnitedHealth Group    3.7\n",
       "6        ₹8L       ₹20L     ₹12,70,000                      Optum    3.7\n",
       "7       ₹10L       ₹18L     ₹14,55,430     Optum Global Solutions       \n",
       "8        ₹5L       ₹15L      ₹8,86,064         Valiance Solutions    4.2\n",
       "9        ₹6L       ₹16L     ₹11,10,000                EXL Service    3.6"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# wait for page load\n",
    "wait_for_page_load('//div[@id=\"nodeReplace\"]//div[@class=\"py css-17435dd\"]')    \n",
    "\n",
    "# finding top 10 boxes \n",
    "all_box = driver.find_elements_by_xpath('//div[@id=\"nodeReplace\"]//div[@class=\"py css-17435dd\"]')[:10]\n",
    "    \n",
    "final_data = []\n",
    "\n",
    "\n",
    "# Ittrating over box to find details\n",
    "for one_box in all_box:\n",
    "    min_salary = one_box.find_elements_by_xpath('.//p')[0].text\n",
    "    max_salary = one_box.find_elements_by_xpath('.//p')[1].text\n",
    "    average_salary = one_box.find_elements_by_xpath('.//h3')[1].text\n",
    "    company_name = one_box.find_elements_by_xpath('.//h3')[0].text\n",
    "    rating = one_box.find_element_by_xpath('.//span').text\n",
    "    \n",
    "    \n",
    "    final_data.append({\n",
    "        'min_salary':min_salary,\n",
    "        'max_salary':max_salary,\n",
    "        'average_salary':average_salary,\n",
    "        'company_name':company_name,\n",
    "        'rating':rating,\n",
    "\n",
    "    })\n",
    "    \n",
    "job_data = pd.DataFrame(final_data)\n",
    "job_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q6 : Scrape data of first 100 sunglasses listings on flipkart.com. You have to scrape four attributes:"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Brand\n",
    "Product Description\n",
    "Price\n",
    "Discount %"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "def flipkart_100(url):\n",
    "    driver=webdriver.Chrome(r\"C:\\Users\\dheerajkumar_pittala\\DataPy\\Browserdrivers\\chromedriver.exe\")\n",
    "    driver.get(url)\n",
    "    \n",
    "    #Closing Pop-up\n",
    "    close_button=driver.find_element_by_xpath(\"//button[@class='_2KpZ6l _2doB4z']\")\n",
    "    close_button.click()    \n",
    "    \n",
    "    \n",
    "    # searching required fields\n",
    "    search=driver.find_element_by_xpath(\"//div[@class='_3OO5Xc']/input\")\n",
    "    search.send_keys('sunglasses')\n",
    "    \n",
    "    search_button=driver.find_element_by_xpath(\"//button[@class='L0Z3Pu']\")\n",
    "    search_button.click()\n",
    "    time.sleep(5)\n",
    "    \n",
    "    brand=[]\n",
    "    des=[]\n",
    "    price=[]\n",
    "    discount=[]\n",
    "    \n",
    "    def extract(driver,number):\n",
    "                \n",
    "        a=driver.find_elements_by_xpath(\"//div[@class='_2WkVRV']\")[:number]\n",
    "        for i in a:\n",
    "            brand.append(i.text)\n",
    "\n",
    "        a=driver.find_elements_by_xpath(\"//div[@class='_2B099V']/a[1]\")[:number]\n",
    "        for i in a:\n",
    "            des.append(i.text)\n",
    "\n",
    "        a=driver.find_elements_by_xpath(\"//div[@class='_2B099V']/a[2]/div/div[1]\")[:number]\n",
    "        for i in a:\n",
    "            price.append(i.text)\n",
    "\n",
    "        a=driver.find_elements_by_xpath(\"//div[@class='_2B099V']/a[2]/div/div[3]\")[:number]\n",
    "        for i in a:\n",
    "            discount.append(i.text)\n",
    "    \n",
    "    while(len(discount)<40):\n",
    "        extract(driver,40)\n",
    "        \n",
    "    while(len(discount)<80):\n",
    "        next=driver.find_element_by_xpath(\"//a[@class='_1LKTO3']\")\n",
    "        driver_2=webdriver.Chrome(r\"C:\\Users\\dheerajkumar_pittala\\DataPy\\Browserdrivers\\chromedriver.exe\")\n",
    "        url=next.get_attribute('href')\n",
    "        driver_2.get(url)\n",
    "        extract(driver_2,40)\n",
    "    \n",
    "    while(len(discount)<100):\n",
    "        next=driver_2.find_element_by_xpath(\"//a[@class='_1LKTO3'][2]\")\n",
    "        driver_3=webdriver.Chrome(r\"C:\\Users\\dheerajkumar_pittala\\DataPy\\Browserdrivers\\chromedriver.exe\")\n",
    "        url=next.get_attribute('href')\n",
    "        driver_3.get(url)\n",
    "        extract(driver_3,20)  \n",
    "    \n",
    "    jobs=pd.DataFrame({})\n",
    "    jobs['brand']=brand\n",
    "    jobs['des']=des\n",
    "    jobs['price']=price\n",
    "    jobs['discount']=discount\n",
    "    \n",
    "    driver.close()\n",
    "    driver_2.close()\n",
    "    driver_3.close()\n",
    "    \n",
    "    return(jobs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>brand</th>\n",
       "      <th>des</th>\n",
       "      <th>price</th>\n",
       "      <th>discount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>AISLIN</td>\n",
       "      <td>UV Protection, Gradient Wayfarer, Clubmaster S...</td>\n",
       "      <td>₹525</td>\n",
       "      <td>65% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>GANSTA</td>\n",
       "      <td>UV Protection Aviator Sunglasses (57)</td>\n",
       "      <td>₹284</td>\n",
       "      <td>85% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>Elligator</td>\n",
       "      <td>UV Protection Round Sunglasses (54)</td>\n",
       "      <td>₹295</td>\n",
       "      <td>88% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>SHAAH COLLECTIONS</td>\n",
       "      <td>UV Protection, Polarized, Mirrored Rectangular...</td>\n",
       "      <td>₹198</td>\n",
       "      <td>88% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>kingsunglasses</td>\n",
       "      <td>Mirrored, UV Protection Wayfarer Sunglasses (F...</td>\n",
       "      <td>₹284</td>\n",
       "      <td>89% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>95</td>\n",
       "      <td>ROYAL SON</td>\n",
       "      <td>Polarized, UV Protection Round Sunglasses (49)</td>\n",
       "      <td>₹664</td>\n",
       "      <td>66% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>96</td>\n",
       "      <td>ROZZETTA CRAFT</td>\n",
       "      <td>Gradient, UV Protection Round Sunglasses (Free...</td>\n",
       "      <td>₹449</td>\n",
       "      <td>77% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>97</td>\n",
       "      <td>PHENOMENAL</td>\n",
       "      <td>UV Protection, Mirrored Clubmaster Sunglasses ...</td>\n",
       "      <td>₹319</td>\n",
       "      <td>84% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>98</td>\n",
       "      <td>AISLIN</td>\n",
       "      <td>UV Protection, Gradient Butterfly, Retro Squar...</td>\n",
       "      <td>₹498</td>\n",
       "      <td>67% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>99</td>\n",
       "      <td>ROYAL SON</td>\n",
       "      <td>UV Protection Retro Square Sunglasses (49)</td>\n",
       "      <td>₹664</td>\n",
       "      <td>66% off</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                brand                                                des  \\\n",
       "0              AISLIN  UV Protection, Gradient Wayfarer, Clubmaster S...   \n",
       "1              GANSTA              UV Protection Aviator Sunglasses (57)   \n",
       "2           Elligator                UV Protection Round Sunglasses (54)   \n",
       "3   SHAAH COLLECTIONS  UV Protection, Polarized, Mirrored Rectangular...   \n",
       "4      kingsunglasses  Mirrored, UV Protection Wayfarer Sunglasses (F...   \n",
       "..                ...                                                ...   \n",
       "95          ROYAL SON     Polarized, UV Protection Round Sunglasses (49)   \n",
       "96     ROZZETTA CRAFT  Gradient, UV Protection Round Sunglasses (Free...   \n",
       "97         PHENOMENAL  UV Protection, Mirrored Clubmaster Sunglasses ...   \n",
       "98             AISLIN  UV Protection, Gradient Butterfly, Retro Squar...   \n",
       "99          ROYAL SON         UV Protection Retro Square Sunglasses (49)   \n",
       "\n",
       "   price discount  \n",
       "0   ₹525  65% off  \n",
       "1   ₹284  85% off  \n",
       "2   ₹295  88% off  \n",
       "3   ₹198  88% off  \n",
       "4   ₹284  89% off  \n",
       "..   ...      ...  \n",
       "95  ₹664  66% off  \n",
       "96  ₹449  77% off  \n",
       "97  ₹319  84% off  \n",
       "98  ₹498  67% off  \n",
       "99  ₹664  66% off  \n",
       "\n",
       "[100 rows x 4 columns]"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=flipkart_100('https://www.flipkart.com/')\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q7: Scrape 100 reviews data from flipkart.com for iphone11 phone. You have to go the link:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://www.flipkart.com/apple-iphone-11-black-64-gb-includes-earpods-power-adapter/p/itm0f37c2240b217?pid=MOBFKCTSVZAXUHGR&lid=LSTMOBFKCTSVZAXUHGREPBFGI&marketplace."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def flipkart_reviews(url):\n",
    "\n",
    "    driver_1 = webdriver.Chrome(r\"C:\\Users\\dheerajkumar_pittala\\DataPy\\Browserdrivers\\chromedriver.exe\")\n",
    "    driver_1.get(url)\n",
    "    \n",
    "    # Opening full reviews\n",
    "    full=driver_1.find_element_by_xpath(\"//div[@class='col JOpGWq']/a\")\n",
    "    driver=webdriver.Chrome(r\"C:\\Users\\dheerajkumar_pittala\\DataPy\\Browserdrivers\\chromedriver.exe\")\n",
    "    url=full.get_attribute('href')\n",
    "    driver.get(url)\n",
    "    driver_1.close()\n",
    "       \n",
    "    rating=[]\n",
    "    review_summary=[]\n",
    "    full_review=[]\n",
    "    \n",
    "    def extract(driver):\n",
    "                \n",
    "        a=driver.find_elements_by_xpath(\"//div[@class='_3LWZlK _1BLPMq']\")\n",
    "        for i in a:\n",
    "            rating.append(i.text)\n",
    "\n",
    "        a=driver.find_elements_by_xpath(\"//p[@class='_2-N8zT']\")\n",
    "        for i in a:\n",
    "            review_summary.append(i.text)\n",
    "\n",
    "        a=driver.find_elements_by_xpath(\"//div[@class='t-ZTKy']/div/div\")\n",
    "        for i in a:\n",
    "            full_review.append(i.text)\n",
    "    \n",
    "    while(len(full_review)<10):\n",
    "        extract(driver)\n",
    "        \n",
    "    while(len(full_review)<100):\n",
    "        next=driver.find_element_by_xpath(\"//a[@class='_1LKTO3']\")\n",
    "        driver=webdriver.Chrome(r\"C:\\Users\\dheerajkumar_pittala\\DataPy\\Browserdrivers\\chromedriver.exe\")\n",
    "        url=next.get_attribute('href')\n",
    "        driver.get(url)\n",
    "        extract(driver)  \n",
    "    \n",
    "    jobs=pd.DataFrame({})\n",
    "    jobs['rating']=rating\n",
    "    jobs['review_summary']=review_summary\n",
    "    jobs['full_review']=full_review\n",
    "    \n",
    "    driver.close()\n",
    "\n",
    "    return(jobs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rating</th>\n",
       "      <th>review_summary</th>\n",
       "      <th>full_review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>Brilliant</td>\n",
       "      <td>The Best Phone for the Money\\n\\nThe iPhone 11 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>Simply awesome</td>\n",
       "      <td>Really satisfied with the Product I received.....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>Best in the market!</td>\n",
       "      <td>Great iPhone very snappy experience as apple k...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>Perfect product!</td>\n",
       "      <td>Amazing phone with great cameras and better ba...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>Fabulous!</td>\n",
       "      <td>This is my first iOS phone. I am very happy wi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>95</td>\n",
       "      <td>5</td>\n",
       "      <td>Highly recommended</td>\n",
       "      <td>It's my first time to use iOS phone and I am l...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>96</td>\n",
       "      <td>5</td>\n",
       "      <td>Perfect product!</td>\n",
       "      <td>Iphone is just awesome.. battery backup is ver...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>97</td>\n",
       "      <td>5</td>\n",
       "      <td>Simply awesome</td>\n",
       "      <td>Excellent camera, good performance, no lag. Th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>98</td>\n",
       "      <td>5</td>\n",
       "      <td>Worth every penny</td>\n",
       "      <td>It’s been almost a month since I have been usi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>99</td>\n",
       "      <td>5</td>\n",
       "      <td>Terrific</td>\n",
       "      <td>Really worth of money. i just love it. It is t...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   rating       review_summary  \\\n",
       "0       5            Brilliant   \n",
       "1       5       Simply awesome   \n",
       "2       5  Best in the market!   \n",
       "3       5     Perfect product!   \n",
       "4       5            Fabulous!   \n",
       "..    ...                  ...   \n",
       "95      5   Highly recommended   \n",
       "96      5     Perfect product!   \n",
       "97      5       Simply awesome   \n",
       "98      5    Worth every penny   \n",
       "99      5             Terrific   \n",
       "\n",
       "                                          full_review  \n",
       "0   The Best Phone for the Money\\n\\nThe iPhone 11 ...  \n",
       "1   Really satisfied with the Product I received.....  \n",
       "2   Great iPhone very snappy experience as apple k...  \n",
       "3   Amazing phone with great cameras and better ba...  \n",
       "4   This is my first iOS phone. I am very happy wi...  \n",
       "..                                                ...  \n",
       "95  It's my first time to use iOS phone and I am l...  \n",
       "96  Iphone is just awesome.. battery backup is ver...  \n",
       "97  Excellent camera, good performance, no lag. Th...  \n",
       "98  It’s been almost a month since I have been usi...  \n",
       "99  Really worth of money. i just love it. It is t...  \n",
       "\n",
       "[100 rows x 3 columns]"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=flipkart_reviews('https://www.flipkart.com/apple-iphone-11-black-64-gb-includes-earpods-power-adapter/p/itm0f37c2240b217?pid=MOBFKCTSVZAXUHGR&lid=LSTMOBFKCTSVZAXUHGREPBFGI&marketplace')\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q8: Scrape data for first 100 sneakers you find when you visit flipkart.com and search for “sneakers” in the search field."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "You have to scrape 4 attributes of each sneaker :\n",
    "\n",
    "Brand\n",
    "Product Description\n",
    "Price\n",
    "discount %"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def flipkart_100_sneakers(url):\n",
    "    driver = webdriver.Chrome(r\"C:\\Users\\dheerajkumar_pittala\\DataPy\\Browserdrivers\\chromedriver.exe\")\n",
    "    driver.get(url)\n",
    "    \n",
    "    #Closing Pop-up\n",
    "    close_button=driver.find_element_by_xpath(\"//button[@class='_2KpZ6l _2doB4z']\")\n",
    "    close_button.click()    \n",
    "    \n",
    "    \n",
    "    # searching required fields\n",
    "    search=driver.find_element_by_xpath(\"//div[@class='_3OO5Xc']/input\")\n",
    "    search.send_keys('sneakers')\n",
    "    \n",
    "    search_button=driver.find_element_by_xpath(\"//button[@class='L0Z3Pu']\")\n",
    "    search_button.click()\n",
    "    time.sleep(5)\n",
    "    \n",
    "    brand=[]\n",
    "    des=[]\n",
    "    price=[]\n",
    "    discount=[]\n",
    "    \n",
    "    def extract(driver,number):\n",
    "                \n",
    "        a=driver.find_elements_by_xpath(\"//div[@class='_2WkVRV']\")[:number]\n",
    "        for i in a:\n",
    "            brand.append(i.text)\n",
    "\n",
    "        a=driver.find_elements_by_xpath(\"//div[@class='_2B099V']/a[1]\")[:number]\n",
    "        for i in a:\n",
    "            des.append(i.text)\n",
    "\n",
    "        a=driver.find_elements_by_xpath(\"//div[@class='_2B099V']/a[2]/div/div[1]\")[:number]\n",
    "        for i in a:\n",
    "            price.append(i.text)\n",
    "\n",
    "        a=driver.find_elements_by_xpath(\"//div[@class='_2B099V']/a[2]/div/div[3]\")[:number]\n",
    "        for i in a:\n",
    "            discount.append(i.text)\n",
    "    \n",
    "    while(len(discount)<40):\n",
    "        extract(driver,40)\n",
    "        \n",
    "    while(len(discount)<80):\n",
    "        next=driver.find_element_by_xpath(\"//a[@class='_1LKTO3']\")\n",
    "        driver_2=webdriver.Chrome(r\"C:\\Users\\dheerajkumar_pittala\\DataPy\\Browserdrivers\\chromedriver.exe\")\n",
    "        url=next.get_attribute('href')\n",
    "        driver_2.get(url)\n",
    "        extract(driver_2,40)\n",
    "    \n",
    "    while(len(discount)<100):\n",
    "        next=driver_2.find_element_by_xpath(\"//a[@class='_1LKTO3'][2]\")\n",
    "        driver_3=webdriver.Chrome(r\"C:\\Users\\dheerajkumar_pittala\\DataPy\\Browserdrivers\\chromedriver.exe\")\n",
    "        url=next.get_attribute('href')\n",
    "        driver_3.get(url)\n",
    "        extract(driver_3,20)  \n",
    "    \n",
    "    jobs=pd.DataFrame({})\n",
    "    jobs['brand']=brand\n",
    "    jobs['des']=des\n",
    "    jobs['price']=price\n",
    "    jobs['discount']=discount\n",
    "    \n",
    "    driver.close()\n",
    "    driver_2.close()\n",
    "    driver_3.close()\n",
    "    \n",
    "    return(jobs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>brand</th>\n",
       "      <th>des</th>\n",
       "      <th>price</th>\n",
       "      <th>discount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>ALBERTO TORRESI</td>\n",
       "      <td>Loafers For Men</td>\n",
       "      <td>₹1,499</td>\n",
       "      <td>74% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>ALBERTO TORRESI</td>\n",
       "      <td>Corporate Casuals For Men</td>\n",
       "      <td>₹1,709</td>\n",
       "      <td>68% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>ALBERTO TORRESI</td>\n",
       "      <td>Casuals For Men</td>\n",
       "      <td>₹1,529</td>\n",
       "      <td>72% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>ALBERTO TORRESI</td>\n",
       "      <td>Men's Faso Brown Formal Slip-ons Casuals For Men</td>\n",
       "      <td>₹1,709</td>\n",
       "      <td>65% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>Venticello</td>\n",
       "      <td>Designer Formal Brogues Brogues For Men</td>\n",
       "      <td>₹890</td>\n",
       "      <td>64% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>95</td>\n",
       "      <td>Zsyto</td>\n",
       "      <td>Sneakers For Men</td>\n",
       "      <td>₹398</td>\n",
       "      <td>69% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>96</td>\n",
       "      <td>HOC</td>\n",
       "      <td>Luxury Fashionable Breathable Casual Sneakers ...</td>\n",
       "      <td>₹398</td>\n",
       "      <td>80% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>97</td>\n",
       "      <td>WRIZT</td>\n",
       "      <td>Casual Sneakers,dancing, walking Sneakers For Men</td>\n",
       "      <td>₹299</td>\n",
       "      <td>70% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>98</td>\n",
       "      <td>Carlo Style</td>\n",
       "      <td>Mens Canvas Shoes for boys (Black) Sneakers Fo...</td>\n",
       "      <td>₹380</td>\n",
       "      <td>61% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>99</td>\n",
       "      <td>BRUTON</td>\n",
       "      <td>Lightweight Pack Of 1 Trendy Sneakers Sneakers...</td>\n",
       "      <td>₹215</td>\n",
       "      <td>64% off</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              brand                                                des  \\\n",
       "0   ALBERTO TORRESI                                    Loafers For Men   \n",
       "1   ALBERTO TORRESI                          Corporate Casuals For Men   \n",
       "2   ALBERTO TORRESI                                    Casuals For Men   \n",
       "3   ALBERTO TORRESI   Men's Faso Brown Formal Slip-ons Casuals For Men   \n",
       "4        Venticello            Designer Formal Brogues Brogues For Men   \n",
       "..              ...                                                ...   \n",
       "95            Zsyto                                   Sneakers For Men   \n",
       "96              HOC  Luxury Fashionable Breathable Casual Sneakers ...   \n",
       "97            WRIZT  Casual Sneakers,dancing, walking Sneakers For Men   \n",
       "98      Carlo Style  Mens Canvas Shoes for boys (Black) Sneakers Fo...   \n",
       "99           BRUTON  Lightweight Pack Of 1 Trendy Sneakers Sneakers...   \n",
       "\n",
       "     price discount  \n",
       "0   ₹1,499  74% off  \n",
       "1   ₹1,709  68% off  \n",
       "2   ₹1,529  72% off  \n",
       "3   ₹1,709  65% off  \n",
       "4     ₹890  64% off  \n",
       "..     ...      ...  \n",
       "95    ₹398  69% off  \n",
       "96    ₹398  80% off  \n",
       "97    ₹299  70% off  \n",
       "98    ₹380  61% off  \n",
       "99    ₹215  64% off  \n",
       "\n",
       "[100 rows x 4 columns]"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=flipkart_100_sneakers('https://www.flipkart.com/')\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q9: Go to the link - https://www.myntra.com/shoes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Set Price filter to “Rs. 6649 to Rs. 13099” [Actual Value for this search = Rs. 7649 to Rs. 15099] , Color filter to “Black”\n",
    "\n",
    "And then scrape First 100 shoes data you get. The data should include “Brand” of the shoes , Short Shoe description, price of the shoe as shown in the below image.\n",
    "\n",
    "Please note that applying the filter and scraping the data , everything should be done through code only and there should not be any manual step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "def myntra(url):\n",
    "    driver = webdriver.Chrome(r\"C:\\Users\\dheerajkumar_pittala\\DataPy\\Browserdrivers\\chromedriver.exe\")\n",
    "    driver.get(url)\n",
    "\n",
    "    # Adding required filters\n",
    "    # [Actual Value for this search = Rs. 7649 to Rs. 15099]\n",
    "    price=driver.find_element_by_xpath(\"//ul[@class='price-list']/li[2]/label/div\")\n",
    "    price.click()\n",
    "    time.sleep(5)\n",
    "    \n",
    "    color=driver.find_element_by_xpath(\"//li[@class='colour-listItem']/label/div\")\n",
    "    color.click()\n",
    "    time.sleep(5)\n",
    "    \n",
    "    brand=[]\n",
    "    des=[]\n",
    "    price=[]\n",
    "    \n",
    "    def extract_2(driver,number):\n",
    "                \n",
    "        a=driver.find_elements_by_xpath(\"//div[@class='product-productMetaInfo']/h3\")[:number]\n",
    "        for i in a:\n",
    "            brand.append(i.text)\n",
    "\n",
    "        a=driver.find_elements_by_xpath(\"//div[@class='product-productMetaInfo']/h4[1]\")[:number]\n",
    "        for i in a:\n",
    "            des.append(i.text)\n",
    "\n",
    "        a=driver.find_elements_by_xpath(\"//div[@class='product-productMetaInfo']/div/span[1]\")[:number]\n",
    "        for i in a:\n",
    "            price.append(i.text)\n",
    "\n",
    "    \n",
    "    while(len(price)<50):\n",
    "        extract_2(driver,50)\n",
    "        \n",
    "    while(len(price)<100):\n",
    "        next=driver.find_element_by_xpath(\"//li[@class='pagination-next']/a\")\n",
    "        driver_2=webdriver.Chrome(r\"C:\\Users\\dheerajkumar_pittala\\DataPy\\Browserdrivers\\chromedriver.exe\")\n",
    "        url=next.get_attribute('href')\n",
    "        driver_2.get(url)\n",
    "        extract_2(driver_2,50) \n",
    "    \n",
    "    jobs=pd.DataFrame({})\n",
    "    jobs['brand']=brand\n",
    "    jobs['des']=des\n",
    "    jobs['price']=price\n",
    "    \n",
    "    driver.close()\n",
    "    driver_2.close()\n",
    "    \n",
    "    return(jobs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>brand</th>\n",
       "      <th>des</th>\n",
       "      <th>price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>Puma</td>\n",
       "      <td>Men BlackTraining or Gym Shoes</td>\n",
       "      <td>Rs. 6999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>Puma</td>\n",
       "      <td>Men Cell Fraction Fade Running</td>\n",
       "      <td>Rs. 6999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>Geox</td>\n",
       "      <td>Men Printed Slip-On Sneakers</td>\n",
       "      <td>Rs. 10999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>Hush Puppies</td>\n",
       "      <td>Men Solid Leather Formal Slip-Ons</td>\n",
       "      <td>Rs. 8099Rs. 8999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>Hush Puppies</td>\n",
       "      <td>Men Solid Leather Formal Slip-Ons</td>\n",
       "      <td>Rs. 8999Rs. 9999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>95</td>\n",
       "      <td>Ruosh</td>\n",
       "      <td>Men Solid Leather Formal Monks</td>\n",
       "      <td>Rs. 8990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>96</td>\n",
       "      <td>Heel &amp; Buckle London</td>\n",
       "      <td>Women Leather Pumps</td>\n",
       "      <td>Rs. 7192Rs. 8990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>97</td>\n",
       "      <td>PUMA Motorsport</td>\n",
       "      <td>Unisex Mercedes F1 Sneakers</td>\n",
       "      <td>Rs. 7999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>98</td>\n",
       "      <td>Puma</td>\n",
       "      <td>Unisex Pacer Future Sneakers</td>\n",
       "      <td>Rs. 6999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>99</td>\n",
       "      <td>Puma</td>\n",
       "      <td>Unisex Mirage Sport Trainers</td>\n",
       "      <td>Rs. 8999</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                   brand                                des             price\n",
       "0                   Puma     Men BlackTraining or Gym Shoes          Rs. 6999\n",
       "1                   Puma     Men Cell Fraction Fade Running          Rs. 6999\n",
       "2                   Geox       Men Printed Slip-On Sneakers         Rs. 10999\n",
       "3           Hush Puppies  Men Solid Leather Formal Slip-Ons  Rs. 8099Rs. 8999\n",
       "4           Hush Puppies  Men Solid Leather Formal Slip-Ons  Rs. 8999Rs. 9999\n",
       "..                   ...                                ...               ...\n",
       "95                 Ruosh     Men Solid Leather Formal Monks          Rs. 8990\n",
       "96  Heel & Buckle London                Women Leather Pumps  Rs. 7192Rs. 8990\n",
       "97       PUMA Motorsport        Unisex Mercedes F1 Sneakers          Rs. 7999\n",
       "98                  Puma       Unisex Pacer Future Sneakers          Rs. 6999\n",
       "99                  Puma       Unisex Mirage Sport Trainers          Rs. 8999\n",
       "\n",
       "[100 rows x 3 columns]"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=myntra('https://www.myntra.com/shoes')\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Please Note: The Price option available on the web page was \"Rs. 7649 to Rs. 15099\" after the search, so results may vary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q10: Go to webpage https://www.amazon.in/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Enter “Laptop” in the search field and then click the search icon. Then set CPU Type filter to “Intel Core i7” and “Intel Core i9”\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "def amazon(url):\n",
    "    driver = webdriver.Chrome(r\"C:\\Users\\dheerajkumar_pittala\\DataPy\\Browserdrivers\\chromedriver.exe\")\n",
    "    driver.get(url)\n",
    "    \n",
    "    search_box=driver.find_element_by_id('twotabsearchtextbox')\n",
    "    search_box.send_keys('laptop')\n",
    "\n",
    "    button=driver.find_element_by_xpath(\"//div[@class='nav-right']\")\n",
    "    button.click()\n",
    "    time.sleep(5)\n",
    "\n",
    "    cpu_1=driver.find_element_by_xpath(\"//div[@id='filters']/ul/li[@aria-label='Intel Core i7']/span/a/div\")\n",
    "    cpu_1.click()\n",
    "\n",
    "    from selenium.common.exceptions import StaleElementReferenceException        # Importing Exception\n",
    "    from selenium.webdriver.support.ui import WebDriverWait\n",
    "    from selenium.webdriver.support import expected_conditions as EC\n",
    "    from selenium.webdriver.common.by import By\n",
    "\n",
    "    try:\n",
    "        cpu_2=driver.find_element_by_xpath(\"//div[@id='filters']/ul/li[@aria-label='Intel Core i9']/span/a/div\")\n",
    "        cpu_2.click()\n",
    "    except StaleElementReferenceException as e:\n",
    "        driver.get('https://www.amazon.in/')\n",
    "        search_box=driver.find_element_by_id('twotabsearchtextbox')\n",
    "        search_box.send_keys('laptop')\n",
    "        button=driver.find_element_by_xpath(\"//div[@class='nav-right']\")\n",
    "        button.click()\n",
    "        WebDriverWait(driver, 10).until(EC.presence_of_element_located((By.ID, 'filters')))\n",
    "        cpu_2=driver.find_element_by_xpath(\"//div[@id='filters']/ul/li[@aria-label='Intel Core i9']/span/a/div\")\n",
    "        cpu_2.click()\n",
    "    \n",
    "    title=[]\n",
    "\n",
    "    a=driver.find_elements_by_xpath(\"//span[@class='a-size-medium a-color-base a-text-normal']\")[:10]\n",
    "    for i in a:\n",
    "        title.append(i.text)\n",
    "\n",
    "    rating=[]\n",
    "\n",
    "    a=driver.find_elements_by_xpath(\"//div[@class='a-row a-size-small']/span/span/a/i/span\")[:10]\n",
    "    for i in a:\n",
    "        rating.append(i.text)\n",
    "\n",
    "    price=[]\n",
    "\n",
    "    a=driver.find_elements_by_xpath(\"//span[@class='a-price-whole']\")[:10]\n",
    "    for i in a:\n",
    "        price.append(i.text)\n",
    "        \n",
    "    jobs=pd.DataFrame({})\n",
    "    jobs['title']=title\n",
    "    jobs['rating']=rating\n",
    "    jobs['price']=price\n",
    "    \n",
    "    driver.close()\n",
    "    return(jobs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>rating</th>\n",
       "      <th>price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>HP Envy 11th Gen Core i7 Processor 13.3-inch (...</td>\n",
       "      <td></td>\n",
       "      <td>1,23,350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>ASUS TUF Dash F15 (2021), 15.6\" (39.62 cms) FH...</td>\n",
       "      <td></td>\n",
       "      <td>95,990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>Mi Notebook Horizon Edition 14 Intel Core i7-1...</td>\n",
       "      <td></td>\n",
       "      <td>57,990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>Lenovo IdeaPad S540 11th Gen Intel Core i7 13....</td>\n",
       "      <td></td>\n",
       "      <td>77,990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>ASUS TUF Dash F15 (2021), 15.6-inch (39.62 cms...</td>\n",
       "      <td></td>\n",
       "      <td>85,990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>ASUS TUF Dash F15 (2021), 15.6-inch (39.62 cms...</td>\n",
       "      <td></td>\n",
       "      <td>84,990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>HP Pavilion 13(2021) 11th Gen Intel Core i7 La...</td>\n",
       "      <td></td>\n",
       "      <td>92,990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>Fujitsu UH-X 11th Gen Intel Core i7 13.3” (33....</td>\n",
       "      <td></td>\n",
       "      <td>1,07,990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>Lenovo IdeaPad Flex 5 11th Gen Intel Core i7 1...</td>\n",
       "      <td></td>\n",
       "      <td>98,500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>ASUS TUF Gaming F17 (2021), 17.3-inch (43.94 c...</td>\n",
       "      <td></td>\n",
       "      <td>1,13,990</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title rating     price\n",
       "0  HP Envy 11th Gen Core i7 Processor 13.3-inch (...         1,23,350\n",
       "1  ASUS TUF Dash F15 (2021), 15.6\" (39.62 cms) FH...           95,990\n",
       "2  Mi Notebook Horizon Edition 14 Intel Core i7-1...           57,990\n",
       "3  Lenovo IdeaPad S540 11th Gen Intel Core i7 13....           77,990\n",
       "4  ASUS TUF Dash F15 (2021), 15.6-inch (39.62 cms...           85,990\n",
       "5  ASUS TUF Dash F15 (2021), 15.6-inch (39.62 cms...           84,990\n",
       "6  HP Pavilion 13(2021) 11th Gen Intel Core i7 La...           92,990\n",
       "7  Fujitsu UH-X 11th Gen Intel Core i7 13.3” (33....         1,07,990\n",
       "8  Lenovo IdeaPad Flex 5 11th Gen Intel Core i7 1...           98,500\n",
       "9  ASUS TUF Gaming F17 (2021), 17.3-inch (43.94 c...         1,13,990"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=amazon('https://www.amazon.in/')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
